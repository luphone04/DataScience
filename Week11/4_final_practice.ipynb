{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "65b567cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   popularity  acousticness  danceability  duration_ms  energy  \\\n",
      "0          41        0.6440         0.823     237000.0   0.814   \n",
      "1          62        0.0855         0.686     154000.0   0.670   \n",
      "2          42        0.2390         0.669     218000.0   0.736   \n",
      "3          64        0.0125         0.522     246000.0   0.923   \n",
      "4          60        0.1210         0.780     229000.0   0.467   \n",
      "\n",
      "   instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n",
      "0          0.687000     0.117    -5.611        0.177  102.619    0.649   \n",
      "1          0.000000     0.120    -7.626        0.225  173.915    0.636   \n",
      "2          0.000169     0.598    -3.223        0.060  145.061    0.494   \n",
      "3          0.017000     0.085    -4.560        0.054  120.406    0.595   \n",
      "4          0.000134     0.314    -6.645        0.253   96.056    0.312   \n",
      "\n",
      "        genre  \n",
      "0        Jazz  \n",
      "1         Rap  \n",
      "2  Electronic  \n",
      "3        Rock  \n",
      "4         Rap  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "music_df = pd.read_csv(\"music.csv\", index_col = 0)\n",
    "print(music_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cd84f143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Anime  Blues  Classical  Country  Electronic  Hip-Hop  Jazz  Rap  Rock\n",
      "0      0      0          0        0           0        0     1    0     0\n",
      "1      0      0          0        0           0        0     0    1     0\n",
      "2      0      0          0        0           1        0     0    0     0\n",
      "3      0      0          0        0           0        0     0    0     1\n",
      "4      0      0          0        0           0        0     0    1     0\n"
     ]
    }
   ],
   "source": [
    "music_dummies = pd.get_dummies(music_df[\"genre\"], drop_first = True)\n",
    "print(music_dummies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "55ed9d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     popularity  acousticness  danceability  duration_ms  energy  \\\n",
      "0            41      0.644000         0.823     237000.0   0.814   \n",
      "1            62      0.085500         0.686     154000.0   0.670   \n",
      "2            42      0.239000         0.669     218000.0   0.736   \n",
      "3            64      0.012500         0.522     246000.0   0.923   \n",
      "4            60      0.121000         0.780     229000.0   0.467   \n",
      "..          ...           ...           ...          ...     ...   \n",
      "995          65      0.000983         0.531     216000.0   0.855   \n",
      "996          38      0.033200         0.608     219000.0   0.938   \n",
      "997          56      0.005790         0.939     145000.0   0.373   \n",
      "998          64      0.250000         0.546     178000.0   0.631   \n",
      "999          61      0.072500         0.641         -1.0   0.792   \n",
      "\n",
      "     instrumentalness  liveness  loudness  speechiness    tempo  ...  \\\n",
      "0            0.687000     0.117    -5.611        0.177  102.619  ...   \n",
      "1            0.000000     0.120    -7.626        0.225  173.915  ...   \n",
      "2            0.000169     0.598    -3.223        0.060  145.061  ...   \n",
      "3            0.017000     0.085    -4.560        0.054  120.406  ...   \n",
      "4            0.000134     0.314    -6.645        0.253   96.056  ...   \n",
      "..                ...       ...       ...          ...      ...  ...   \n",
      "995          0.000000     0.072    -4.950        0.035  124.578  ...   \n",
      "996          0.000000     0.310    -2.681        0.287  134.198  ...   \n",
      "997          0.000000     0.274    -7.779        0.227  119.953  ...   \n",
      "998          0.000000     0.123    -5.757        0.028  129.556  ...   \n",
      "999          0.513000     0.175    -6.453        0.027   87.069  ...   \n",
      "\n",
      "          genre Anime  Blues  Classical  Country  Electronic  Hip-Hop  Jazz  \\\n",
      "0          Jazz     0      0          0        0           0        0     1   \n",
      "1           Rap     0      0          0        0           0        0     0   \n",
      "2    Electronic     0      0          0        0           1        0     0   \n",
      "3          Rock     0      0          0        0           0        0     0   \n",
      "4           Rap     0      0          0        0           0        0     0   \n",
      "..          ...   ...    ...        ...      ...         ...      ...   ...   \n",
      "995        Rock     0      0          0        0           0        0     0   \n",
      "996  Electronic     0      0          0        0           1        0     0   \n",
      "997         Rap     0      0          0        0           0        0     0   \n",
      "998        Rock     0      0          0        0           0        0     0   \n",
      "999        Rock     0      0          0        0           0        0     0   \n",
      "\n",
      "     Rap  Rock  \n",
      "0      0     0  \n",
      "1      1     0  \n",
      "2      0     0  \n",
      "3      0     1  \n",
      "4      1     0  \n",
      "..   ...   ...  \n",
      "995    0     1  \n",
      "996    0     0  \n",
      "997    1     0  \n",
      "998    0     1  \n",
      "999    0     1  \n",
      "\n",
      "[1000 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "music_dummies = pd.concat([music_df , music_dummies], axis = 1)\n",
    "print(music_dummies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "85c1ccab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     popularity  acousticness  danceability  duration_ms  energy  \\\n",
      "0            41      0.644000         0.823     237000.0   0.814   \n",
      "1            62      0.085500         0.686     154000.0   0.670   \n",
      "2            42      0.239000         0.669     218000.0   0.736   \n",
      "3            64      0.012500         0.522     246000.0   0.923   \n",
      "4            60      0.121000         0.780     229000.0   0.467   \n",
      "..          ...           ...           ...          ...     ...   \n",
      "995          65      0.000983         0.531     216000.0   0.855   \n",
      "996          38      0.033200         0.608     219000.0   0.938   \n",
      "997          56      0.005790         0.939     145000.0   0.373   \n",
      "998          64      0.250000         0.546     178000.0   0.631   \n",
      "999          61      0.072500         0.641         -1.0   0.792   \n",
      "\n",
      "     instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n",
      "0            0.687000     0.117    -5.611        0.177  102.619    0.649   \n",
      "1            0.000000     0.120    -7.626        0.225  173.915    0.636   \n",
      "2            0.000169     0.598    -3.223        0.060  145.061    0.494   \n",
      "3            0.017000     0.085    -4.560        0.054  120.406    0.595   \n",
      "4            0.000134     0.314    -6.645        0.253   96.056    0.312   \n",
      "..                ...       ...       ...          ...      ...      ...   \n",
      "995          0.000000     0.072    -4.950        0.035  124.578    0.424   \n",
      "996          0.000000     0.310    -2.681        0.287  134.198    0.436   \n",
      "997          0.000000     0.274    -7.779        0.227  119.953    0.060   \n",
      "998          0.000000     0.123    -5.757        0.028  129.556    0.569   \n",
      "999          0.513000     0.175    -6.453        0.027   87.069    0.670   \n",
      "\n",
      "     Anime  Blues  Classical  Country  Electronic  Hip-Hop  Jazz  Rap  Rock  \n",
      "0        0      0          0        0           0        0     1    0     0  \n",
      "1        0      0          0        0           0        0     0    1     0  \n",
      "2        0      0          0        0           1        0     0    0     0  \n",
      "3        0      0          0        0           0        0     0    0     1  \n",
      "4        0      0          0        0           0        0     0    1     0  \n",
      "..     ...    ...        ...      ...         ...      ...   ...  ...   ...  \n",
      "995      0      0          0        0           0        0     0    0     1  \n",
      "996      0      0          0        0           1        0     0    0     0  \n",
      "997      0      0          0        0           0        0     0    1     0  \n",
      "998      0      0          0        0           0        0     0    0     1  \n",
      "999      0      0          0        0           0        0     0    0     1  \n",
      "\n",
      "[1000 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "music_dummies = music_dummies.drop(\"genre\", axis = 1)\n",
    "print(music_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "81cbd9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=42, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you already have music_dummies DataFrame\n",
    "\n",
    "#feature matrix X\n",
    "X = music_dummies.drop(\"popularity\", axis=1).values\n",
    "\n",
    "#feature matrix y\n",
    "y = music_dummies[\"popularity\"].values\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now you can proceed with your linear regression or other modeling tasks\n",
    "#5 splits is created (n_splits=5) along with shuffling of data and setting a random seed (shuffle=True, random_state=42)\n",
    "kf = KFold(n_splits = 5, shuffle = True,  random_state = 42)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "71511559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.15810501 8.63114581 7.52281687 8.62016985 7.91296943]\n"
     ]
    }
   ],
   "source": [
    "# An instance of a linear regression model is created and stored in the variable linreg.\n",
    "linreg = LinearRegression()\n",
    "\n",
    "#Cross-validation is performed using the linear regression model (linreg) with the \n",
    "#negative mean squared error (neg_mean_squared_error) as the scoring metric. \n",
    "#This line calculates RMSE for each fold.\n",
    "linreg_cv = cross_val_score(linreg , X_train, y_train, cv = kf , scoring = \"neg_mean_squared_error\")\n",
    "\n",
    "#prints the RMSE values for each fold of cross-validation.\n",
    "print(np.sqrt(-linreg_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cf78c847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.823</td>\n",
       "      <td>237000.0</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-5.611</td>\n",
       "      <td>0.177</td>\n",
       "      <td>102.619</td>\n",
       "      <td>0.649</td>\n",
       "      <td>Jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.686</td>\n",
       "      <td>154000.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-7.626</td>\n",
       "      <td>0.225</td>\n",
       "      <td>173.915</td>\n",
       "      <td>0.636</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.669</td>\n",
       "      <td>218000.0</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.598</td>\n",
       "      <td>-3.223</td>\n",
       "      <td>0.060</td>\n",
       "      <td>145.061</td>\n",
       "      <td>0.494</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.522</td>\n",
       "      <td>246000.0</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-4.560</td>\n",
       "      <td>0.054</td>\n",
       "      <td>120.406</td>\n",
       "      <td>0.595</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.780</td>\n",
       "      <td>229000.0</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.314</td>\n",
       "      <td>-6.645</td>\n",
       "      <td>0.253</td>\n",
       "      <td>96.056</td>\n",
       "      <td>0.312</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>65</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.531</td>\n",
       "      <td>216000.0</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-4.950</td>\n",
       "      <td>0.035</td>\n",
       "      <td>124.578</td>\n",
       "      <td>0.424</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>38</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.608</td>\n",
       "      <td>219000.0</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-2.681</td>\n",
       "      <td>0.287</td>\n",
       "      <td>134.198</td>\n",
       "      <td>0.436</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>56</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.939</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-7.779</td>\n",
       "      <td>0.227</td>\n",
       "      <td>119.953</td>\n",
       "      <td>0.060</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>64</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.546</td>\n",
       "      <td>178000.0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-5.757</td>\n",
       "      <td>0.028</td>\n",
       "      <td>129.556</td>\n",
       "      <td>0.569</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>61</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-6.453</td>\n",
       "      <td>0.027</td>\n",
       "      <td>87.069</td>\n",
       "      <td>0.670</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0            41      0.644000         0.823     237000.0   0.814   \n",
       "1            62      0.085500         0.686     154000.0   0.670   \n",
       "2            42      0.239000         0.669     218000.0   0.736   \n",
       "3            64      0.012500         0.522     246000.0   0.923   \n",
       "4            60      0.121000         0.780     229000.0   0.467   \n",
       "..          ...           ...           ...          ...     ...   \n",
       "995          65      0.000983         0.531     216000.0   0.855   \n",
       "996          38      0.033200         0.608     219000.0   0.938   \n",
       "997          56      0.005790         0.939     145000.0   0.373   \n",
       "998          64      0.250000         0.546     178000.0   0.631   \n",
       "999          61      0.072500         0.641         -1.0   0.792   \n",
       "\n",
       "     instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n",
       "0            0.687000     0.117    -5.611        0.177  102.619    0.649   \n",
       "1            0.000000     0.120    -7.626        0.225  173.915    0.636   \n",
       "2            0.000169     0.598    -3.223        0.060  145.061    0.494   \n",
       "3            0.017000     0.085    -4.560        0.054  120.406    0.595   \n",
       "4            0.000134     0.314    -6.645        0.253   96.056    0.312   \n",
       "..                ...       ...       ...          ...      ...      ...   \n",
       "995          0.000000     0.072    -4.950        0.035  124.578    0.424   \n",
       "996          0.000000     0.310    -2.681        0.287  134.198    0.436   \n",
       "997          0.000000     0.274    -7.779        0.227  119.953    0.060   \n",
       "998          0.000000     0.123    -5.757        0.028  129.556    0.569   \n",
       "999          0.513000     0.175    -6.453        0.027   87.069    0.670   \n",
       "\n",
       "          genre  \n",
       "0          Jazz  \n",
       "1           Rap  \n",
       "2    Electronic  \n",
       "3          Rock  \n",
       "4           Rap  \n",
       "..          ...  \n",
       "995        Rock  \n",
       "996  Electronic  \n",
       "997         Rap  \n",
       "998        Rock  \n",
       "999        Rock  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c86350ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>0.610</td>\n",
       "      <td>217000.0</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-7.325</td>\n",
       "      <td>0.036</td>\n",
       "      <td>137.838</td>\n",
       "      <td>0.352</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>0.565</td>\n",
       "      <td>261000.0</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-9.309</td>\n",
       "      <td>0.024</td>\n",
       "      <td>75.537</td>\n",
       "      <td>0.229</td>\n",
       "      <td>Anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>0.433</td>\n",
       "      <td>263000.0</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-3.658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.358</td>\n",
       "      <td>0.461</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.359</td>\n",
       "      <td>564000.0</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-8.323</td>\n",
       "      <td>0.032</td>\n",
       "      <td>89.259</td>\n",
       "      <td>0.167</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037</td>\n",
       "      <td>120.406</td>\n",
       "      <td>0.496</td>\n",
       "      <td>Anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597</td>\n",
       "      <td>183000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.501</td>\n",
       "      <td>-4.727</td>\n",
       "      <td>0.110</td>\n",
       "      <td>87.479</td>\n",
       "      <td>0.866</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.348</td>\n",
       "      <td>188000.0</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-4.589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.043</td>\n",
       "      <td>0.392</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.608</td>\n",
       "      <td>219000.0</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-2.681</td>\n",
       "      <td>0.287</td>\n",
       "      <td>134.198</td>\n",
       "      <td>0.436</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691</td>\n",
       "      <td>199000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-10.843</td>\n",
       "      <td>0.039</td>\n",
       "      <td>135.954</td>\n",
       "      <td>0.613</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519</td>\n",
       "      <td>409000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-6.850</td>\n",
       "      <td>0.030</td>\n",
       "      <td>125.844</td>\n",
       "      <td>0.152</td>\n",
       "      <td>Blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0          64.0      0.694000         0.610     217000.0   0.590   \n",
       "1          31.0      0.739000         0.565     261000.0   0.393   \n",
       "2          57.0      0.008790         0.433     263000.0   0.815   \n",
       "3          63.0      0.010500         0.359     564000.0   0.762   \n",
       "4           NaN      0.301000         0.511          NaN   0.699   \n",
       "..          ...           ...           ...          ...     ...   \n",
       "995        59.0           NaN         0.597     183000.0     NaN   \n",
       "996        61.0      0.000484         0.348     188000.0   0.893   \n",
       "997        38.0      0.033200         0.608     219000.0   0.938   \n",
       "998        63.0           NaN         0.691     199000.0     NaN   \n",
       "999        34.0           NaN         0.519     409000.0     NaN   \n",
       "\n",
       "     instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n",
       "0            0.000002     0.150    -7.325        0.036  137.838    0.352   \n",
       "1            0.000845     0.143    -9.309        0.024   75.537    0.229   \n",
       "2            0.000000     0.138    -3.658          NaN  125.358    0.461   \n",
       "3            0.281000     0.368    -8.323        0.032   89.259    0.167   \n",
       "4                 NaN     0.088       NaN        0.037  120.406    0.496   \n",
       "..                ...       ...       ...          ...      ...      ...   \n",
       "995          0.001910     0.501    -4.727        0.110   87.479    0.866   \n",
       "996          0.000064     0.281    -4.589          NaN  148.043    0.392   \n",
       "997          0.000000     0.310    -2.681        0.287  134.198    0.436   \n",
       "998          0.000684     0.119   -10.843        0.039  135.954    0.613   \n",
       "999          0.007870     0.337    -6.850        0.030  125.844    0.152   \n",
       "\n",
       "          genre  \n",
       "0           NaN  \n",
       "1         Anime  \n",
       "2          Rock  \n",
       "3          Rock  \n",
       "4         Anime  \n",
       "..          ...  \n",
       "995        Rock  \n",
       "996        Rock  \n",
       "997  Electronic  \n",
       "998        Rock  \n",
       "999       Blues  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df = pd.read_csv('music_unclean.csv', index_col=0)\n",
    "music_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa0f98d",
   "metadata": {},
   "source": [
    "# CLEANING data\n",
    "# MISSING data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d4814b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre                 8\n",
      "popularity           31\n",
      "loudness             44\n",
      "liveness             46\n",
      "tempo                46\n",
      "speechiness          59\n",
      "duration_ms          91\n",
      "instrumentalness     91\n",
      "danceability        143\n",
      "valence             143\n",
      "acousticness        200\n",
      "energy              200\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# sort the columns based on the number of missing values in ascending order.\n",
    "#result is a Series containing the count of missing values for each column.\n",
    "print(music_df.isna().sum().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4f913",
   "metadata": {},
   "source": [
    "# DROPPING Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "eb83c4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity            0\n",
      "liveness              0\n",
      "loudness              0\n",
      "tempo                 0\n",
      "genre                 0\n",
      "duration_ms          29\n",
      "instrumentalness     29\n",
      "speechiness          53\n",
      "danceability        127\n",
      "valence             127\n",
      "acousticness        178\n",
      "energy              178\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"]) \n",
    "print (music_df.isna().sum().sort_values ())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73639797",
   "metadata": {},
   "source": [
    "# IMPUTATION WITH SCKIKIT LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bd026125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#.reshape() method is used to change the shape of the NumPy array. \n",
    "#In this case, it reshapes the array into a two-dimensional array with a single column \n",
    "X_cat = music_df[\"genre\"].values.reshape(-1,1)\n",
    "\n",
    "#The axis=1 parameter specifies that columns should be dropped, not rows.\n",
    "X_num = music_df.drop([\"genre\", \"popularity\"], axis=1).values\n",
    "\n",
    "# target variable\n",
    "y = music_df[\"popularity\"].values\n",
    "\n",
    "\n",
    "# splits your data into training and testing sets for both categorical and numerical features. \n",
    "#This parameter specifies that 20% of the data should be used for testing, while the remaining 80% will be used for training.\n",
    "#X_cat: This variable represents the categorical features\n",
    "X_train_cat , X_test_cat, y_train, y_test = train_test_split(X_cat, y, test_size =0.2, random_state = 12)\n",
    "\n",
    "# Similar to the previous line, this parameter specifies a 20% test size.\n",
    "##X_num: This variable represents the categorical features\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_num, y , test_size=0.2, random_state=12)\n",
    "\n",
    "#SimpleImputer is a scikit-learn class used to fill in missing values in datasets.\n",
    "#\"most_frequent\" strategy means that the imputer will replace missing values with the most \n",
    "#frequent value (mode) observed in each column.\n",
    "imp_cat = SimpleImputer(strategy = \"most_frequent\")\n",
    "\n",
    "\n",
    "# to fill missing values in your categorical features (X_train_cat and X_test_cat) with the most frequent values. \n",
    "#on the training data (X_train_cat) using the fit_transform method\n",
    "X_train_cat = imp_cat.fit_transform(X_train_cat)\n",
    "# transform the testing data (X_test_cat) without re-fitting it.\n",
    "X_test_cat = imp_cat.transform(X_test_cat)\n",
    "\n",
    "# similar to what you did for imputing categorical features, but it's applied to numerical features \n",
    "#(X_train_num and X_test_num) using a different SimpleImputer object (imp_num). \n",
    "#without specifying a strategy, which means it will default to using the \"mean\" strategy \n",
    "imp_num = SimpleImputer()\n",
    "# calculates the mean value for each column in X_train_num and replaces any missing values with those means.\n",
    "X_train_num = imp_num.fit_transform(X_train_num)\n",
    "# uses the already fitted SimpleImputer (imp_num) to transform the testing data (X_test_num) without re-fitting it. \n",
    "#It replaces missing values in X_test_num with the means\n",
    "X_test_num = imp_num.transform(X_test_num)\n",
    "\n",
    "# combining the imputed numerical and categorical features to create the final feature matrices for \n",
    "#training and testing.\n",
    "# contains all the features for the training set, with numerical features followed by categorical features.\n",
    "X_train = np.append(X_train_num, X_train_cat, axis = 1)\n",
    "# contains all the features for the testing set in the same order as X_train\n",
    "X_test = np.append(X_test_num, X_test_cat, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "34db84c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "columns = ['acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "       'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo',\n",
    "       'valence', 'genre']\n",
    "check = pd.DataFrame(X_train, columns = columns)\n",
    "print(check.isna().sum().sort_values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7d02e6bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Jazz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4j/bnvctt7152z6l5l6szd4m7wh0000gn/T/ipykernel_92928/851459051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# trains the KNN classifier using the training data X_train and corresponding labels y_train.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#This step is where the model learns from the training data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requires_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                 X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    455\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Jazz'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# consider the 5 nearest neighbors when making predictions.\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "# trains the KNN classifier using the training data X_train and corresponding labels y_train. \n",
    "#This step is where the model learns from the training data.\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Evaluating the model's accuracy\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5244d0",
   "metadata": {},
   "source": [
    "# IMPUTING WITH A PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3206e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#or binary classification (Rock vs. Not Rock) and using a pipeline to streamline \n",
    "#your data preprocessing and modeling workflow\n",
    "\n",
    "# removes rows from the DataFrame music_df where any of the specified columns \n",
    "#(\"genre,\" \"popularity,\" \"loudness,\" \"liveness,\" \"tempo\") have missing values (NaN). \n",
    "#It effectively removes rows that are incomplete in terms of these columns.\n",
    "music_df = music_df.dropna(subset = [\"genre\", \"popularity\" ,\"loudness\", \"liveness\", \"tempo\"])\n",
    "\n",
    "#converts the \"genre\" column into binary labels. It assigns a label of 1 to rows where \n",
    "#the \"genre\" is \"Rock\" and a label of 0 to rows where it is not \"Rock.\"\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "# extracts the feature matrix X by dropping the \"genre\" column from music_df. \n",
    "#It contains all the features except the target variable.\n",
    "X = music_df.drop(\"genre\", axis = 1).values\n",
    "\n",
    "# extracts the target variable y, which is the \"genre\" column \n",
    "y = music_df[\"genre\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0d244774",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4j/bnvctt7152z6l5l6szd4m7wh0000gn/T/ipykernel_92928/758042883.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#s represent the feature matrices and target vectors for both the training and testing datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1242\u001b[0m                 \u001b[0;34m\"This solver needs samples of at least 2 classes\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# LogisticRegression for logistic regression modeling.\n",
    "# Pipeline to create a pipeline that automates data preprocessing and model training.\n",
    "# SimpleImputer for imputing missing values.\n",
    "\n",
    "steps = [(\"imputation\", SimpleImputer()), (\"logistic_regression\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "#s represent the feature matrices and target vectors for both the training and testing datasets\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size =0.3, random_state = 42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a4d40bcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4j/bnvctt7152z6l5l6szd4m7wh0000gn/T/ipykernel_92928/1011547198.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Fit the pipeline on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Predict on the testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1242\u001b[0m                 \u001b[0;34m\"This solver needs samples of at least 2 classes\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the pipeline with imputation and logistic regression\n",
    "steps = [(\"imputation\", SimpleImputer()), (\"logistic_regression\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance on the testing data\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3303d5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 79  56]\n",
      " [ 23 110]]\n",
      "0.7052238805970149\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "music_df = pd.read_csv('music_unclean.csv', index_col = 0)\n",
    "\n",
    "#Drops rows with missing values in specific columns ('genre', 'popularity', 'loudness', 'liveness', 'tempo')\n",
    "music_df = music_df.dropna(subset=['genre', 'popularity','loudness','liveness','tempo']) \n",
    "#Converts the 'genre' column into a binary classification problem by mapping 'Rock' to 1 and everything else to 0.\n",
    "music_df['genre'] = np.where(music_df['genre'] == 'Rock', 1, 0)\n",
    "\n",
    "#Separates the feature matrix X (all columns except 'genre') and the target vector y ('genre').\n",
    "X = music_df.drop('genre', axis = 1).values\n",
    "y = music_df['genre'].values\n",
    "#Splits the data into training and testing sets using train_test_split with a test size of 30% and a random state of 42.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "# a list of pipeline steps consisting of two components:\n",
    "# Imputation: Missing value imputation using SimpleImputer (missing data is filled with the mean of the non-missing values).\n",
    "# Logistic Regression: Classification using logistic regression\n",
    "steps = [('imputation', SimpleImputer()), ('Log_reg', LogisticRegression())]\n",
    "\n",
    "#passing the list of steps to the Pipeline constructor.\n",
    "pipeline = Pipeline(steps) \n",
    "\n",
    "#e pipeline to the training data, which includes both imputation and logistic regression steps.\n",
    "pipeline.fit(X_train, y_train)\n",
    "#fitted pipeline to make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test) \n",
    "\n",
    "# The top-left cell (79) represents True Negatives (TN). These are instances where the model correctly predicted a negative class (0 in your case).\n",
    "# The top-right cell (56) represents False Positives (FP). These are instances where the model incorrectly predicted a positive class (1) when the actual class was negative.\n",
    "# The bottom-left cell (23) represents False Negatives (FN). These are instances where the model incorrectly predicted a negative class when the actual class was positive.\n",
    "# The bottom-right cell (110) represents True Positives (TP). These are instances where the model correctly predicted a positive class.\n",
    "print(confusion_matrix(y_test, y_pred)) \n",
    "\n",
    "# represents the proportion of correctly classified instances (both True Positives and True Negatives) out of the total instances in the test set.\n",
    "# In this case, it means that your logistic regression model achieved an accuracy of approximately 70.52%. This suggests that about 70.52% of the test instances were correctly classified by the model.\n",
    "print(pipeline.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704bf8de",
   "metadata": {},
   "source": [
    "Handling Missing Data, Imputing Data and Pipelining\n",
    "\n",
    "You are going to tidy the music_df dataset. You will create a pipeline to impute missing values and build a KNN classifier model, then use it to predict whether a song is of the \"Rock\" genre.\n",
    "\n",
    "In this exercise specifically, you will drop missing values accounting for less than 5% of the dataset, and convert the \"genre\" column into a binary feature.\n",
    "\n",
    "Instructions:\n",
    "• Load the music_df from music_unclean.csv and print the number of missing values for each column in the music_df dataset,\n",
    "sorted in ascending order.\n",
    "\n",
    "• Remove values for all columns with 50 or fewer missing values.\n",
    "\n",
    "• Convert music_df[\"genre\"] to values of 1 if the row contains \"Rock\", otherwise change the value to 0.\n",
    "\n",
    "• X = all columns except genre\n",
    "\n",
    "• y = genre\n",
    "\n",
    "• Split data with test_size = 30 and random state set to 42\n",
    "\n",
    "• Instantiate an imputer.\n",
    "\n",
    "• Instantiate a KNN classifier with three neighbors.\n",
    "\n",
    "• Create steps, a list of tuples containing the imputer variable you created, called \"imputer\", followed by the knn model you\n",
    "created, called \"knn\".\n",
    "\n",
    "• Create a pipeline using the steps you previously defined.\n",
    "\n",
    "• Fit the pipeline to the training data.\n",
    "\n",
    "• Make predictions on the test set.\n",
    "\n",
    "• Calculate and print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3c10e8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre                 8\n",
      "popularity           31\n",
      "loudness             44\n",
      "liveness             46\n",
      "tempo                46\n",
      "speechiness          59\n",
      "duration_ms          91\n",
      "instrumentalness     91\n",
      "danceability        143\n",
      "valence             143\n",
      "acousticness        200\n",
      "energy              200\n",
      "dtype: int64\n",
      "          genre  popularity  loudness  liveness    tempo\n",
      "0           NaN        64.0    -7.325     0.150  137.838\n",
      "1         Anime        31.0    -9.309     0.143   75.537\n",
      "2          Rock        57.0    -3.658     0.138  125.358\n",
      "3          Rock        63.0    -8.323     0.368   89.259\n",
      "4         Anime         NaN       NaN     0.088  120.406\n",
      "..          ...         ...       ...       ...      ...\n",
      "995        Rock        59.0    -4.727     0.501   87.479\n",
      "996        Rock        61.0    -4.589     0.281  148.043\n",
      "997  Electronic        38.0    -2.681     0.310  134.198\n",
      "998        Rock        63.0   -10.843     0.119  135.954\n",
      "999       Blues        34.0    -6.850     0.337  125.844\n",
      "\n",
      "[1000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "music_df = pd.read_csv(\"music_unclean.csv\", index_col = 0)\n",
    "missing_values = music_df.isna().sum().sort_values()\n",
    "print(missing_values)\n",
    "\n",
    "# Remove columns with 50 or fewer missing values\n",
    "columns_to_keep = missing_values[missing_values <= 50].index\n",
    "music_df = music_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "76710c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "genre                 8\n",
      "popularity           31\n",
      "loudness             44\n",
      "liveness             46\n",
      "tempo                46\n",
      "speechiness          59\n",
      "duration_ms          91\n",
      "instrumentalness     91\n",
      "danceability        143\n",
      "valence             143\n",
      "acousticness        200\n",
      "energy              200\n",
      "dtype: int64\n",
      "Confusion Matrix:\n",
      "[[109  30]\n",
      " [ 39 122]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "music_df = pd.read_csv('music_unclean.csv', index_col=0)\n",
    "\n",
    "# Print the number of missing values for each column, sorted in ascending order\n",
    "missing_values = music_df.isna().sum().sort_values()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Remove columns with 50 or fewer missing values\n",
    "columns_to_keep = missing_values[missing_values <= 50].index\n",
    "music_df = music_df[columns_to_keep]\n",
    "\n",
    "# Convert \"genre\" column to binary (1 for \"Rock\" and 0 for other genres)\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "# Define X and y\n",
    "X = music_df.drop(\"genre\", axis=1)\n",
    "y = music_df[\"genre\"]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "# Instantiate a KNN classifier with three neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Create steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), (\"knn\", knn)]\n",
    "\n",
    "# Create a pipeline using the defined steps\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f1b9b4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "genre                 8\n",
      "popularity           31\n",
      "loudness             44\n",
      "liveness             46\n",
      "tempo                46\n",
      "speechiness          59\n",
      "duration_ms          91\n",
      "instrumentalness     91\n",
      "danceability        143\n",
      "valence             143\n",
      "acousticness        200\n",
      "energy              200\n",
      "dtype: int64\n",
      "Confusion Matrix:\n",
      "[[109  30]\n",
      " [ 39 122]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "music_df = pd.read_csv('music_unclean.csv', index_col=0)\n",
    "\n",
    "# Print the number of missing values for each column, sorted in ascending order\n",
    "missing_values = music_df.isnull().sum().sort_values()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Remove columns with 50 or fewer missing values\n",
    "columns_to_keep = missing_values[missing_values <= 50].index\n",
    "music_df = music_df[columns_to_keep]\n",
    "\n",
    "# Convert \"genre\" column to binary (1 for \"Rock\" and 0 for other genres)\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "# Define X and y\n",
    "X = music_df.drop(\"genre\", axis=1)\n",
    "y = music_df[\"genre\"]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate an imputer and fit it to the training data\n",
    "imputer = SimpleImputer()\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Instantiate a KNN classifier with three neighbors and fit it to the training data\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test_imputed)\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5c9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
