{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c023ae58",
   "metadata": {},
   "source": [
    "# CLASSWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "631782ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          2         7         10        14\n",
      "2   1.000000  0.298902  0.271207  0.123121\n",
      "7   0.298902  1.000000  0.322330  0.051345\n",
      "10  0.271207  0.322330  1.000000  0.063692\n",
      "14  0.123121  0.051345  0.063692  1.000000\n",
      "Accuracy of logistic regression classifier:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4j/bnvctt7152z6l5l6szd4m7wh0000gn/T/ipykernel_23995/1641907923.py:20: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  cc_apps_train.fillna(cc_apps_train.mean(), inplace=True)\n",
      "/var/folders/4j/bnvctt7152z6l5l6szd4m7wh0000gn/T/ipykernel_23995/1641907923.py:21: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  cc_apps_test.fillna(cc_apps_train.mean(), inplace=True)\n",
      "/Users/richard/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[103,   0],\n",
       "       [  0, 125]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "cc_apps = pd.read_csv(\"cc_approvals.data\", header=None)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(cc_apps.corr())\n",
    "\n",
    "#Drop the features 11 and 13\n",
    "cc_apps = cc_apps.drop([11, 13], axis=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "cc_apps_train, cc_apps_test = train_test_split(cc_apps, test_size=0.33, random_state=42)\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Replace the '?'s with NaN in the train and test sets\n",
    "cc_apps_train = cc_apps_train.replace('?', np.NaN)\n",
    "cc_apps_test = cc_apps_test.replace('?', np.NaN)\n",
    "cc_apps_train.fillna(cc_apps_train.mean(), inplace=True)\n",
    "cc_apps_test.fillna(cc_apps_train.mean(), inplace=True)\n",
    "for col in cc_apps_train.columns: # Iterate over each column of cc_apps_train\n",
    "\n",
    "    if cc_apps_train[col].dtypes == 'object': # Check if the column is of object type\n",
    "        # Impute with the most frequent value\n",
    "        # The value_counts() function returns a Series that contain counts of unique values. It returns an object that will be in \n",
    "        # descending order so that its first element will be the most frequently-occurred element.\n",
    "        cc_apps_train = cc_apps_train.fillna(cc_apps_train[col].value_counts().index[0])\n",
    "        cc_apps_test = cc_apps_test.fillna(cc_apps_train[col].value_counts().index[0])\n",
    "        \n",
    "cc_apps_train = pd.get_dummies(cc_apps_train)\n",
    "cc_apps_test = pd.get_dummies(cc_apps_test)\n",
    "cc_apps_test = cc_apps_test.reindex(columns=cc_apps_train.columns, fill_value=0)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Segregate features and labels into separate variables\n",
    "X_train, y_train = cc_apps_train.iloc[:, :-1].values, cc_apps_train.iloc[:, [-1]].values\n",
    "X_test, y_test = cc_apps_test.iloc[:, :-1].values, cc_apps_test.iloc[:, [-1]].values\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.transform(X_test)\n",
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit logreg to the train set\n",
    "logreg.fit(rescaledX_train,y_train)\n",
    "# Import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Use logreg to predict instances from the test set and store it\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "# Get the accuracy score of logreg model and print it\n",
    "print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test,y_test))\n",
    "\n",
    "# Print the confusion matrix of the logreg model\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58df90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import GridSearchCV\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define the grid of values for tol and max_iter\n",
    "# tol = [0.01, 0.001 ,0.0001]\n",
    "# max_iter = [100, 150, 200]\n",
    "\n",
    "# # Create a dictionary where tol and max_iter are keys and the lists of their values are corresponding values\n",
    "# param_grid = dict(tol=tol, max_iter=max_iter)\n",
    "# # Instantiate GridSearchCV with the required parameters\n",
    "# grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n",
    "\n",
    "# # Fit data to grid_model\n",
    "# grid_model_result = grid_model.fit(rescaledX, y)\n",
    "\n",
    "# # Summarize results\n",
    "# best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
    "# print(\"Best: %f using %s\" % (best_score, best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e9f75",
   "metadata": {},
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7016a1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1: Accuracy = 0.9048153342683497\n",
      "K = 2: Accuracy = 0.9090696587190275\n",
      "K = 3: Accuracy = 0.9176718092566618\n",
      "K = 4: Accuracy = 0.9111266947171576\n",
      "K = 5: Accuracy = 0.9089294062646097\n",
      "K = 6: Accuracy = 0.9089527816736792\n",
      "K = 7: Accuracy = 0.9241701729780271\n",
      "K = 8: Accuracy = 0.9285179990649837\n",
      "K = 9: Accuracy = 0.9307152875175315\n",
      "K = 10: Accuracy = 0.9307620383356708\n",
      "K = 11: Accuracy = 0.926437587657784\n",
      "K = 12: Accuracy = 0.9328892005610097\n",
      "K = 13: Accuracy = 0.9329125759700794\n",
      "K = 14: Accuracy = 0.9307386629266012\n",
      "K = 15: Accuracy = 0.935063113604488\n",
      "K = 16: Accuracy = 0.9328892005610099\n",
      "K = 17: Accuracy = 0.9263674614305751\n",
      "K = 18: Accuracy = 0.9242402992052361\n",
      "K = 19: Accuracy = 0.9155913978494624\n",
      "K = 20: Accuracy = 0.9112435717625058\n",
      "\n",
      "Best K value: 15\n",
      "Best accuracy: 0.935063113604488\n",
      "Confusion Matrix:\n",
      " [[ 93  10]\n",
      " [  7 118]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define a range of K values to try\n",
    "param_grid = {'n_neighbors': range(1, 21)}  # Try K values from 1 to 20\n",
    "\n",
    "# Create a grid search using cross-validation\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "grid_search.fit(rescaledX_train, y_train.ravel())  # Using ravel() to convert y_train to 1D array\n",
    "\n",
    "# Print accuracy for each K value\n",
    "for params, accuracy in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score']):\n",
    "    k = params['n_neighbors']\n",
    "    print(f\"K = {k}: Accuracy = {accuracy}\")\n",
    "\n",
    "# Get the best K value and its corresponding accuracy\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"\\nBest K value:\", best_k)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "\n",
    "# Create a KNeighborsClassifier with the best K value\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_knn.fit(rescaledX_train, y_train.ravel())\n",
    "\n",
    "# Use the best_knn to predict and calculate test accuracy\n",
    "y_pred_test = best_knn.predict(rescaledX_test)\n",
    "#test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "#print(\"\\nTest accuracy with best K:\", test_accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ddab85",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d88852fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier:  1.0\n",
      "Confusion Matrix:\n",
      " [[103   0]\n",
      " [  0 125]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4j/bnvctt7152z6l5l6szd4m7wh0000gn/T/ipykernel_23995/2160929429.py:13: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  cc_apps.fillna(cc_apps.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "cc_apps = pd.read_csv(\"cc_approvals.data\", header=None)\n",
    "cc_apps = cc_apps.drop([11, 13], axis=1)\n",
    "# Replace the '?'s with NaN\n",
    "cc_apps = cc_apps.replace('?', np.NaN)\n",
    "cc_apps.fillna(cc_apps.mean(), inplace=True)\n",
    "\n",
    "# Impute missing values with the most frequent value for each column\n",
    "for col in cc_apps.columns:\n",
    "    if cc_apps[col].dtypes == 'object':\n",
    "        cc_apps = cc_apps.fillna(cc_apps[col].value_counts().index[0])\n",
    "\n",
    "# Perform one-hot encoding on categorical features\n",
    "cc_apps = pd.get_dummies(cc_apps)\n",
    "\n",
    "# Split into features (X) and target labels (y)\n",
    "X = cc_apps.iloc[:, :-1].values  # Use all columns except the last one as features\n",
    "y = cc_apps.iloc[:, -1].values   # Use the last column as the target label\n",
    "\n",
    "# Scale the features to a range between 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(rescaledX, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Instantiate and train the Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy of the Logistic Regression model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of logistic regression classifier: \", accuracy)\n",
    "\n",
    "# Print the confusion matrix of the Logistic Regression model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33232e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af814ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
